{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ea5296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded. Train: (11017, 35) Test present: True\n",
      "Numeric features: 33 Categorical: 5 Binned: ['Age', 'CreditScore']\n",
      "Starting cross-validated evaluation (5 folds)...\n",
      "Fold 1 | ROC-AUC: 0.9828 | PR-AUC: 0.9840\n",
      "Fold 2 | ROC-AUC: 0.9845 | PR-AUC: 0.9857\n",
      "Fold 3 | ROC-AUC: 0.9844 | PR-AUC: 0.9858\n",
      "Fold 4 | ROC-AUC: 0.9846 | PR-AUC: 0.9856\n",
      "Fold 5 | ROC-AUC: 0.9851 | PR-AUC: 0.9861\n",
      "\n",
      "OOF CV ROC-AUC: 0.9842\n",
      "OOF CV PR-AUC: 0.9854\n",
      "Precision: 0.9349, Recall: 0.9370, F1: 0.9360\n",
      "\n",
      "Training final model on full train...\n",
      "Saved submission to: submission_lab2.csv\n",
      "\n",
      "Done. Если ROC-AUC (OOF) < 0.75, рекомендую:\n",
      "  • увеличить SelectKBest (k), попробовать passthrough=True в StackingClassifier,\n",
      "  • тонкая настройка RandomForest (max_depth, n_estimators) или замена HGB на LightGBM,\n",
      "  • добавить дополнительные interaction-признаки или использовать target-encoding для категорий.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer, StandardScaler, KBinsDiscretizer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_fscore_support\n",
    "from sklearn.base import clone\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "train_path = 'mai-ml-lab-2-fiit-2025/train_c.csv'\n",
    "test_path  = 'mai-ml-lab-2-fiit-2025/test_c.csv'\n",
    "submission_path = 'submission_lab2.csv'\n",
    "\n",
    "def safe_log1p_ser(s):\n",
    "    s = pd.to_numeric(s, errors='coerce').copy()\n",
    "    if s.isnull().all():\n",
    "        return s\n",
    "    mn = s.min(skipna=True)\n",
    "    if pd.notna(mn) and mn < 0:\n",
    "        shift = abs(mn) + 1.0\n",
    "        return np.log1p(s + shift)\n",
    "    else:\n",
    "        return np.log1p(s.fillna(0))\n",
    "\n",
    "if not os.path.exists(train_path):\n",
    "    raise FileNotFoundError(f\"Train file not found at {train_path}\")\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path) if os.path.exists(test_path) else None\n",
    "print(\"Loaded. Train:\", train_df.shape, \"Test present:\", test_df is not None)\n",
    "\n",
    "def preprocess_base(df, is_train=True):\n",
    "    df = df.copy()\n",
    "    if is_train and 'LoanApproved' in df.columns:\n",
    "        df = df[df['LoanApproved'].isin([0,1]) | df['LoanApproved'].isna()] if 'LoanApproved' in df.columns else df\n",
    "    df.replace(-9999999.0, np.nan, inplace=True)\n",
    "    if 'ApplicationDate' in df.columns:\n",
    "        df['ApplicationDate'] = pd.to_datetime(df['ApplicationDate'], errors='coerce')\n",
    "        df['App_Year'] = df['ApplicationDate'].dt.year.fillna(0).astype(int)\n",
    "        df['App_Month'] = df['ApplicationDate'].dt.month.fillna(0).astype(int)\n",
    "        df['App_DayOfWeek'] = df['ApplicationDate'].dt.dayofweek.fillna(0).astype(int)\n",
    "    eps = 1e-6\n",
    "    if 'MonthlyLoanPayment' in df.columns and 'MonthlyIncome' in df.columns:\n",
    "        df['PaymentToIncomeRatio'] = df['MonthlyLoanPayment'] / (df['MonthlyIncome'] + eps)\n",
    "    if 'LoanAmount' in df.columns and 'AnnualIncome' in df.columns:\n",
    "        df['LoanToIncomeRatio'] = df['LoanAmount'] / (df['AnnualIncome'] + eps)\n",
    "    if 'TotalLiabilities' in df.columns and 'TotalAssets' in df.columns:\n",
    "        df['DebtToAssetsRatio'] = df['TotalLiabilities'] / (df['TotalAssets'] + eps)\n",
    "    if 'SavingsAccountBalance' in df.columns and 'LoanAmount' in df.columns:\n",
    "        df['SavingsToLoanRatio'] = df['SavingsAccountBalance'] / (df['LoanAmount'] + eps)\n",
    "    if 'LengthOfCreditHistory' in df.columns and 'PaymentHistory' in df.columns:\n",
    "        df['CreditHistoryInteraction'] = df['LengthOfCreditHistory'] * df['PaymentHistory']\n",
    "    if 'MonthlyIncome' in df.columns and 'CreditScore' in df.columns:\n",
    "        df['Income_x_CreditScore'] = df['MonthlyIncome'].fillna(0) * df['CreditScore'].fillna(0)\n",
    "    clip_cols = ['MonthlyIncome','LoanAmount','AnnualIncome','SavingsAccountBalance','TotalAssets','TotalLiabilities','MonthlyDebtPayments']\n",
    "    for c in clip_cols:\n",
    "        if c in df.columns:\n",
    "            lo = df[c].quantile(0.01)\n",
    "            hi = df[c].quantile(0.99)\n",
    "            df[c] = df[c].clip(lo, hi)\n",
    "    log_candidates = ['MonthlyIncome','LoanAmount','SavingsAccountBalance','CheckingAccountBalance','TotalAssets','TotalLiabilities','NetWorth','MonthlyDebtPayments']\n",
    "    for c in log_candidates:\n",
    "        if c in df.columns:\n",
    "            df[c] = safe_log1p_ser(df[c])\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    return df\n",
    "\n",
    "train_proc = preprocess_base(train_df, is_train=True)\n",
    "test_proc = preprocess_base(test_df, is_train=False) if test_df is not None else None\n",
    "\n",
    "target_col = 'LoanApproved'\n",
    "numerical_candidates = [\n",
    "    'CreditScore','MonthlyIncome','BaseInterestRate','LoanAmount','LoanDuration',\n",
    "    'DebtToIncomeRatio','NumberOfDependents','NumberOfOpenCreditLines','NumberOfCreditInquiries',\n",
    "    'PaymentHistory','LengthOfCreditHistory','UtilityBillsPaymentHistory','MonthlyDebtPayments',\n",
    "    'CreditCardUtilizationRate','InterestRate','TotalDebtToIncomeRatio','SavingsAccountBalance',\n",
    "    'CheckingAccountBalance','TotalAssets','TotalLiabilities','NetWorth','JobTenure','Experience','Age',\n",
    "    'BankruptcyHistory','PreviousLoanDefaults','PaymentToIncomeRatio','LoanToIncomeRatio','DebtToAssetsRatio',\n",
    "    'SavingsToLoanRatio','CreditHistoryInteraction','Income_x_CreditScore','App_Year','App_Month','App_DayOfWeek'\n",
    "]\n",
    "numerical = [c for c in numerical_candidates if c in train_proc.columns]\n",
    "categorical_candidates = ['MaritalStatus','HomeOwnershipStatus','EmploymentStatus','EducationLevel','LoanPurpose']\n",
    "categorical = [c for c in categorical_candidates if c in train_proc.columns]\n",
    "binned = [c for c in ['Age','CreditScore'] if c in train_proc.columns]\n",
    "\n",
    "final_numerical = [c for c in numerical if c not in binned]\n",
    "all_features = final_numerical + categorical + binned\n",
    "\n",
    "def drop_high_corr(df, features, thresh=0.99):\n",
    "    num_df = df[features].select_dtypes(include=[np.number]).copy()\n",
    "    if num_df.shape[1] < 2:\n",
    "        return []\n",
    "    corr = num_df.corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    to_drop = [col for col in upper.columns if any(upper[col] > thresh)]\n",
    "    return to_drop\n",
    "\n",
    "to_drop = drop_high_corr(train_proc, final_numerical, thresh=0.995)\n",
    "if to_drop:\n",
    "    final_numerical = [f for f in final_numerical if f not in to_drop]\n",
    "    all_features = final_numerical + categorical + binned\n",
    "\n",
    "print(\"Numeric features:\", len(final_numerical), \"Categorical:\", len(categorical), \"Binned:\", binned)\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('power', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "binned_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('bin', KBinsDiscretizer(n_bins=10, encode='onehot-dense', strategy='quantile'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_pipeline, final_numerical),\n",
    "    ('cat', categorical_pipeline, categorical),\n",
    "    ('bin', binned_pipeline, binned)\n",
    "], remainder='drop')\n",
    "\n",
    "train_proc = train_proc.dropna(subset=[target_col], how='any')\n",
    "X = train_proc[all_features].copy()\n",
    "y = train_proc[target_col].astype(int).copy()\n",
    "\n",
    "if test_proc is not None:\n",
    "    for c in all_features:\n",
    "        if c not in test_proc.columns:\n",
    "            test_proc[c] = np.nan\n",
    "\n",
    "\n",
    "clf_lr = LogisticRegression(C=1.0, solver='saga', max_iter=5000, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "clf_rf = RandomForestClassifier(n_estimators=300, max_depth=10, n_jobs=-1, random_state=RANDOM_STATE)\n",
    "clf_hgb = HistGradientBoostingClassifier(max_iter=300, random_state=RANDOM_STATE)\n",
    "\n",
    "estimators = [\n",
    "    ('lr', clf_lr),\n",
    "    ('rf', clf_rf),\n",
    "    ('hgb', clf_hgb)\n",
    "]\n",
    "final_meta = LogisticRegression(solver='liblinear', C=1.0, random_state=RANDOM_STATE)\n",
    "\n",
    "pipe_stack = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('pre_var', SelectKBest(score_func=f_classif, k=min(800, max(10, len(final_numerical) + 100)))),\n",
    "    ('stack', StackingClassifier(estimators=estimators, final_estimator=final_meta, n_jobs=-1, passthrough=False))\n",
    "])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"Starting cross-validated evaluation (5 folds)...\")\n",
    "oof_preds = np.zeros(len(X))\n",
    "for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "    y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "    pipe = clone(pipe_stack)\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "    proba = pipe.predict_proba(X_val)[:,1]\n",
    "    oof_preds[val_idx] = proba\n",
    "    auc = roc_auc_score(y_val, proba)\n",
    "    ap = average_precision_score(y_val, proba)\n",
    "    print(f\"Fold {fold} | ROC-AUC: {auc:.4f} | PR-AUC: {ap:.4f}\")\n",
    "\n",
    "cv_auc = roc_auc_score(y, oof_preds)\n",
    "cv_pr = average_precision_score(y, oof_preds)\n",
    "print(f\"\\nOOF CV ROC-AUC: {cv_auc:.4f}\")\n",
    "print(f\"OOF CV PR-AUC: {cv_pr:.4f}\")\n",
    "\n",
    "y_pred_bin = (oof_preds >= 0.5).astype(int)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y, y_pred_bin, average='binary')\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "print(\"\\nTraining final model on full train...\")\n",
    "pipe_stack.fit(X, y)\n",
    "\n",
    "if test_proc is not None:\n",
    "    X_test = test_proc[all_features].copy()\n",
    "    preds_test_proba = pipe_stack.predict_proba(X_test)[:,1]\n",
    "    preds_test_proba = np.clip(preds_test_proba, 0.0, 1.0)\n",
    "    if 'ID' in test_proc.columns:\n",
    "        sub = pd.DataFrame({'ID': test_proc['ID'], 'LoanApproved': preds_test_proba})\n",
    "    else:\n",
    "        sub = pd.DataFrame({'LoanApproved': preds_test_proba})\n",
    "    sub.to_csv(submission_path, index=False)\n",
    "    print(\"Saved submission to:\", submission_path)\n",
    "\n",
    "print(\"\\nDone. Если ROC-AUC (OOF) < 0.75, рекомендую:\")\n",
    "print(\"  • увеличить SelectKBest (k), попробовать passthrough=True в StackingClassifier,\")\n",
    "print(\"  • тонкая настройка RandomForest (max_depth, n_estimators) или замена HGB на LightGBM,\")\n",
    "print(\"  • добавить дополнительные interaction-признаки или использовать target-encoding для категорий.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
